<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v4.12.2"><title>Chat with your documents using ChatGPT | NuNmi.ai</title><link rel="canonical" href="https://astronaut.github.io/website/blog/chat-with-your-documents/"><meta name="description" content="NuNmi.ai offers expert consulting and courses in machine learning and engineering."><meta name="robots" content="index, follow"><meta property="og:title" content="NuNmi.ai - Empowering Your Success"><meta property="og:type" content="website"><meta property="og:image" content="https://astronaut.github.io/opengraph.jpg"><meta property="og:url" content="https://astronaut.github.io/website/blog/chat-with-your-documents/"><meta property="og:image:url" content="https://astronaut.github.io/opengraph.jpg"><meta property="og:image:alt" content="NuNmi.ai Homepage Screenshot"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@nunmi_ai"><meta name="twitter:creator" content="@nunmi_ai"><link rel="stylesheet" href="/website/_astro/about.DrTvtidS.css"></head> <body> <div class="max-w-screen-xl mx-auto px-5">  <header class="flex flex-col lg:flex-row justify-between items-center my-5">  <div class="flex w-full lg:w-auto items-center justify-between"> <a href="/" class="text-lg"> <span class="font-bold text-slate-800">NuNmi</span><span class="text-slate-500">.ai</span> </a> <div class="block lg:hidden"> <button id="astronav-menu" aria-label="Toggle Menu">  <svg fill="currentColor" class="w-4 h-4 text-gray-800" width="24" height="24" viewBox="0 0 24 24" xmlns="https://www.w3.org/2000/svg"> <title>Toggle Menu</title> <path class="astronav-close-icon astronav-toggle hidden" fill-rule="evenodd" clip-rule="evenodd" d="M18.278 16.864a1 1 0 01-1.414 1.414l-4.829-4.828-4.828 4.828a1 1 0 01-1.414-1.414l4.828-4.829-4.828-4.828a1 1 0 011.414-1.414l4.829 4.828 4.828-4.828a1 1 0 111.414 1.414l-4.828 4.829 4.828 4.828z"></path> <path class="astronav-open-icon astronav-toggle" fill-rule="evenodd" d="M4 5h16a1 1 0 010 2H4a1 1 0 110-2zm0 6h16a1 1 0 010 2H4a1 1 0 010-2zm0 6h16a1 1 0 010 2H4a1 1 0 010-2z"></path> </svg>  </button> </div> </div> <nav class="astronav-items astronav-toggle hidden w-full lg:w-auto mt-2 lg:flex lg:mt-0">  <ul class="flex flex-col lg:flex-row lg:gap-3"> <li> <a href="/about" class="flex lg:px-3 py-2 items-center text-gray-600 hover:text-gray-900"> <span> About</span>  </a> </li><li> <a href="/blog" class="flex lg:px-3 py-2 items-center text-gray-600 hover:text-gray-900"> <span> Blog</span>  </a> </li><li> <a href="/contact" class="flex lg:px-3 py-2 items-center text-gray-600 hover:text-gray-900"> <span> Contact</span>  </a> </li> </ul>   </nav>  <script>(function(){const closeOnClick = false;

["DOMContentLoaded", "astro:after-swap"].forEach((event) => {
  document.addEventListener(event, addListeners);
});

// Function to clone and replace elements
function cloneAndReplace(element) {
  const clone = element.cloneNode(true);
  element.parentNode.replaceChild(clone, element);
}

function addListeners() {
  // Clean up existing listeners
  const oldMenuButton = document.getElementById("astronav-menu");
  if (oldMenuButton) {
    cloneAndReplace(oldMenuButton);
  }

  const oldDropdownMenus = document.querySelectorAll(".astronav-dropdown");
  oldDropdownMenus.forEach((menu) => {
    cloneAndReplace(menu);
  });

  // Mobile nav toggle
  const menuButton = document.getElementById("astronav-menu");
  menuButton && menuButton.addEventListener("click", toggleMobileNav);

  // Dropdown menus
  const dropdownMenus = document.querySelectorAll(".astronav-dropdown");
  dropdownMenus.forEach((menu) => {
    const button = menu.querySelector("button");
    button &&
      button.addEventListener("click", (event) =>
        toggleDropdownMenu(event, menu, dropdownMenus)
      );

    // Handle Submenu Dropdowns
    const dropDownSubmenus = menu.querySelectorAll(
      ".astronav-dropdown-submenu"
    );

    dropDownSubmenus.forEach((submenu) => {
      const submenuButton = submenu.querySelector("button");
      submenuButton &&
        submenuButton.addEventListener("click", (event) => {
          event.stopImmediatePropagation();
          toggleSubmenuDropdown(event, submenu);
        });
    });
  });

  // Clicking away from dropdown will remove the dropdown class
  document.addEventListener("click", closeAllDropdowns);

  if (closeOnClick) {
    handleCloseOnClick();
  }
}

function toggleMobileNav() {
  [...document.querySelectorAll(".astronav-toggle")].forEach((el) => {
    el.classList.toggle("hidden");
  });
}

function toggleDropdownMenu(event, menu, dropdownMenus) {
  toggleMenu(menu);

  // Close one dropdown when selecting another
  Array.from(dropdownMenus)
    .filter((el) => el !== menu && !menu.contains(el))
    .forEach(closeMenu);

  event.stopPropagation();
}

function toggleSubmenuDropdown(event, submenu) {
  event.stopPropagation();
  toggleMenu(submenu);

  // Close sibling submenus at the same nesting level
  const siblingSubmenus = submenu
    .closest(".astronav-dropdown")
    .querySelectorAll(".astronav-dropdown-submenu");
  Array.from(siblingSubmenus)
    .filter((el) => el !== submenu && !submenu.contains(el))
    .forEach(closeMenu);
}

function closeAllDropdowns(event) {
  const dropdownMenus = document.querySelectorAll(".dropdown-toggle");
  const dropdownParent = document.querySelectorAll(
    ".astronav-dropdown, .astronav-dropdown-submenu"
  );
  const isButtonInsideDropdown = [
    ...document.querySelectorAll(
      ".astronav-dropdown button, .astronav-dropdown-submenu button, #astronav-menu"
    ),
  ].some((button) => button.contains(event.target));
  if (!isButtonInsideDropdown) {
    dropdownMenus.forEach((d) => {
      // console.log("I ran", d);
      // if (!d.contains(event.target)) {
      d.classList.remove("open");
      d.removeAttribute("open");
      d.classList.add("hidden");
      // }
    });
    dropdownParent.forEach((d) => {
      d.classList.remove("open");
      d.removeAttribute("open");
      d.setAttribute("aria-expanded", "false");
    });
  }
}

function toggleMenu(menu) {
  menu.classList.toggle("open");
  const expanded = menu.getAttribute("aria-expanded") === "true";
  menu.setAttribute("aria-expanded", expanded ? "false" : "true");
  menu.hasAttribute("open")
    ? menu.removeAttribute("open")
    : menu.setAttribute("open", "");

  const dropdownToggle = menu.querySelector(".dropdown-toggle");
  const dropdownExpanded = dropdownToggle.getAttribute("aria-expanded");
  dropdownToggle.classList.toggle("hidden");
  dropdownToggle.setAttribute(
    "aria-expanded",
    dropdownExpanded === "true" ? "false" : "true"
  );
}

function closeMenu(menu) {
  // console.log("closing", menu);
  menu.classList.remove("open");
  menu.removeAttribute("open");
  menu.setAttribute("aria-expanded", "false");
  const dropdownToggles = menu.querySelectorAll(".dropdown-toggle");
  dropdownToggles.forEach((toggle) => {
    toggle.classList.add("hidden");
    toggle.setAttribute("aria-expanded", "false");
  });
}

function handleCloseOnClick() {
  const navMenuItems = document.querySelector(".astronav-items");
  const navToggle = document.getElementById("astronav-menu");
  const navLink = navMenuItems && navMenuItems.querySelectorAll("a");

  const MenuIcons = navToggle.querySelectorAll(".astronav-toggle");

  navLink &&
    navLink.forEach((item) => {
      item.addEventListener("click", () => {
        navMenuItems?.classList.add("hidden");
        MenuIcons.forEach((el) => {
          el.classList.toggle("hidden");
        });
      });
    });
}
})();</script> <!-- <div>
      <div class="hidden lg:flex items-center gap-4">
        <Link href="/login">Log in</Link>
        <Link href="/signup" size="md">Sign up</Link>
      </div>
    </div> --> </header>  </div>  <div class="max-w-screen-xl mx-auto px-5">  <div class="mx-auto max-w-3xl mt-14"> <span class="text-blue-400 uppercase tracking-wider text-sm font-medium"> Tutorials </span> <h1 class="text-4xl lg:text-5xl font-bold lg:tracking-tight mt-1 lg:leading-tight"> Chat with your documents using ChatGPT </h1> <div class="flex gap-2 mt-3 items-center flex-wrap md:flex-nowrap"> <!-- <span class="text-gray-400">{entry.data.author}</span> --> <!-- <span class="text-gray-400">•</span> --> <time class="text-gray-400" datetime="2023-05-06T06:09:00.000Z"> Sat May 06 2023 </time> <span class="text-gray-400 hidden md:block">•</span> <div class="w-full md:w-auto flex flex-wrap gap-3"> <span class="text-sm text-gray-500">#ChatGPT</span><span class="text-sm text-gray-500">#OpenAI</span><span class="text-sm text-gray-500">#RAG</span> </div> </div> </div> <div class="mx-auto prose prose-lg mt-6 max-w-3xl"> <p>Ever since <a href="https://openai.com/">OpenAI</a> announced their language model <a href="https://openai.com/blog/chatgpt">ChatGPT</a>, it has been making headlines in the AI world on a daily basis. ChatGPT is being used as the foundation for countless new tools and applications, ranging from customer service chatbots to creative writing assistants. With its ability to generate high-quality, human-like responses to complex prompts, ChatGPT has quickly become a game-changing technology.</p>
<p>The applications of LLMs like ChatGPT are virtually limitless. Our imagination would be the only barrier. In this blog series though, We’ll be focusing on how we can make ChatGPT, or any LLM for that matter to answer our queries with the context of the custom knowledge from the documents we feed to it. We’ll start off with a simpler implementation using <a href="https://github.com/jerryjliu/llama_index">Llama-index</a> that reads almost all types of basic document formats and returns the response to your queries based upon it. As we progress, we’ll be using <a href="https://python.langchain.com/en/latest/index.html">Langchain</a> to build a full fledged chatbot framework that reads the content from almost any link or document that you give to it and answers your queries accordingly. Langchain is a great framework for developing applications powered by language models. We’ll be building a web app using these frameworks. Exciting times ahead !</p>
<h3 id="let-me-lay-the-prerequisites-first">Let me lay the <strong>prerequisites</strong> first:</h3>
<ul>
<li>You will need a working OpenAI key, because we’ll be using the GPT-3 model underneath. If you don’t have one, here’s <a href="https://www.howtogeek.com/885918/how-to-get-an-openai-api-key/">how to get an OpenAI API Key</a></li>
<li>You need to have python>=3.6 installed in your machine</li>
</ul>
<p>That’s about everything you’d need. Rest of the things we’ll take care of, as we sail through. Now without further ado, let’s dive right in.</p>
<hr>
<h2 id="behold-the-power-of-llama-index-llama">Behold, the power of Llama-Index :llama:</h2>
<p>As I said earlier, We are gonna use llama_index for this tutorial. We are not building anything fancy as of now. We’ll not be building any UI. The sole purpose of this is to give an understanding of how llama_index works underneath. Below is the implementation using llama_index and langchain. llama_index uses langchain models under the hood.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">from</span><span style="color:#E1E4E8"> gpt_index </span><span style="color:#F97583">import</span><span style="color:#E1E4E8"> download_loader, SimpleDirectoryReader, GPTSimpleVectorIndex, LLMPredictor, PromptHelper</span></span>
<span class="line"><span style="color:#F97583">from</span><span style="color:#E1E4E8"> langchain.chat_models </span><span style="color:#F97583">import</span><span style="color:#E1E4E8"> ChatOpenAI</span></span>
<span class="line"><span style="color:#F97583">import</span><span style="color:#E1E4E8"> os</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">os.environ[</span><span style="color:#9ECBFF">"OPENAI_API_KEY"</span><span style="color:#E1E4E8">] </span><span style="color:#F97583">=</span><span style="color:#9ECBFF"> 'Your API Key Here'</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">file_path </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> input</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">'Enter the path of the file/doc: '</span><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> build_index</span><span style="color:#E1E4E8">(file_path):</span></span>
<span class="line"><span style="color:#E1E4E8">    max_input_size </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 4096</span></span>
<span class="line"><span style="color:#E1E4E8">    num_outputs </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 512</span></span>
<span class="line"><span style="color:#E1E4E8">    max_chunk_overlap </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 20</span></span>
<span class="line"><span style="color:#E1E4E8">    chunk_size_limit </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 256</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">    prompt_helper </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> PromptHelper(max_input_size, num_outputs, max_chunk_overlap, </span><span style="color:#FFAB70">chunk_size_limit</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">chunk_size_limit)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">    llm_predictor </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> LLMPredictor(</span><span style="color:#FFAB70">llm</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">ChatOpenAI(</span><span style="color:#FFAB70">temperature</span><span style="color:#F97583">=</span><span style="color:#79B8FF">0.7</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">model_name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"gpt-3.5-turbo"</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">max_tokens</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">num_outputs))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">    download_loader(</span><span style="color:#9ECBFF">'SimpleDirectoryReader'</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#E1E4E8">    documents </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> SimpleDirectoryReader(</span><span style="color:#FFAB70">input_files</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[file_path]).load_data()</span></span>
<span class="line"><span style="color:#E1E4E8">    index </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> GPTSimpleVectorIndex(documents, </span><span style="color:#FFAB70">llm_predictor</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_predictor, </span><span style="color:#FFAB70">prompt_helper</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">prompt_helper)</span></span>
<span class="line"><span style="color:#F97583">    return</span><span style="color:#E1E4E8"> index</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">index </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> build_index(</span><span style="color:#FFAB70">file_path</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">file_path)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> chatbot</span><span style="color:#E1E4E8">(prompt):</span></span>
<span class="line"><span style="color:#F97583">    return</span><span style="color:#E1E4E8"> index.query(prompt, </span><span style="color:#FFAB70">response_mode</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"compact"</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#E1E4E8">   </span></span>
<span class="line"><span style="color:#F97583">while</span><span style="color:#79B8FF"> True</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#79B8FF">    print</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">'########################################'</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#E1E4E8">    pt </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> input</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">'ASK: '</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#F97583">    if</span><span style="color:#E1E4E8"> pt.lower()</span><span style="color:#F97583">==</span><span style="color:#9ECBFF">'end'</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#F97583">        break</span></span>
<span class="line"><span style="color:#E1E4E8">    response </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> chatbot(pt)</span></span>
<span class="line"><span style="color:#79B8FF">    print</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">'----------------------------------------'</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#79B8FF">    print</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">'ChatGPT says: '</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#79B8FF">    print</span><span style="color:#E1E4E8">(response)</span></span>
<span class="line"></span></code></pre>
<p>Copy the above code in entirety and paste it in a file and name it whatever you want. I’m naming it <code>main.py</code>. Replace the API key placeholder in the code, with your own OpenAI API key and you are done.</p>
<p>First up, run the below command to install the libraries that we’d need:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>pip3 install gpt_index==0.4.24 &#x26;&#x26; pip3 install langchain==0.0.142</span></span>
<span class="line"><span></span></span></code></pre>
<p>You can run the code by running this command <code>python3 main.py</code> at the location of this file, when prompted give the path of your context file to the program. I’m using Martin Luther King’s “<a href="https://www.btboces.org/Downloads/I%20Have%20a%20Dream%20by%20Martin%20Luther%20King%20Jr.pdf">I have a dream</a>” speech transcript PDF file.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#B392F0">➜</span><span style="color:#9ECBFF">  python3</span><span style="color:#9ECBFF"> main.py</span></span>
<span class="line"><span style="color:#B392F0">Enter</span><span style="color:#9ECBFF"> the</span><span style="color:#9ECBFF"> path</span><span style="color:#9ECBFF"> of</span><span style="color:#9ECBFF"> the</span><span style="color:#9ECBFF"> file/doc:</span><span style="color:#9ECBFF"> blogs/docbot/martin.pdf</span></span>
<span class="line"></span></code></pre>
<p>You can give any type of file format. Depending on the file
size and your machine’s power, it’ll take some time to read and convert your file contents into vectors. In my case, it takes around 10 seconds to process a 30MB document.</p>
<p>Once it is done, you can start asking questions to your document using ChatGPT. Below are some of the example prompts and responses.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>ASK: </span></span>
<span class="line"><span></span></span>
<span class="line"><span>what is this document about?</span></span>
<span class="line"><span></span></span>
<span class="line"><span>----------------------------------------</span></span>
<span class="line"><span></span></span>
<span class="line"><span>ChatGPT says: </span></span>
<span class="line"><span></span></span>
<span class="line"><span>The document is about a speech or written piece that discusses</span></span>
<span class="line"><span>the promise of equal rights for all Americans, particularly</span></span>
<span class="line"><span>black Americans, as outlined in the Constitution and Declaration of Independence.</span></span>
<span class="line"><span>It addresses the fact that this promise has not been fully</span></span>
<span class="line"><span>realized and that there is a shameful condition that needs to be dramatized.  </span></span>
<span class="line"><span></span></span></code></pre>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>ASK: </span></span>
<span class="line"><span></span></span>
<span class="line"><span>summarize the speech</span></span>
<span class="line"><span></span></span>
<span class="line"><span>----------------------------------------</span></span>
<span class="line"><span></span></span>
<span class="line"><span>ChatGPT says: </span></span>
<span class="line"><span></span></span>
<span class="line"><span>The speech urges America to remember the importance of freedom and justice, and emphasizes the urgent</span></span>
<span class="line"><span>need for action in the face of racial injustice. The speaker encourages the audience to rise above </span></span>
<span class="line"><span>segregation and work towards brotherhood. The overall message is that now is the time to make real the</span></span>
<span class="line"><span>promises of democracy. </span></span>
<span class="line"><span></span></span></code></pre>
<p>That’s it. As simple as that. 35 lines of code. Llama-Index and other tools like it have made it so easy and user friendly to leverage the full power of LLMs.</p>
<hr>
<h2 id="okay-thats-cool-but-what-really-happens-underneath">Okay that’s cool, but what really happens underneath?</h2>
<p>Llama-index and langchain have made the whole process very seamless, which otherwise would’ve been a really cumbersome task. So, here’s what happens:</p>
<ul>
<li>
<p>When you give llama_index the document, it uses one of the adapters that actually suits for the file type from the collection of pre-built adapters from the <a href="https://llamahub.ai/">Llama-Hub</a> and parses the contents of the file.</p>
</li>
<li>
<p>Once the parsing is done, llama_index converts the whole content into chunks of vectors.</p>
</li>
<li>
<p>When you put up a question to ChatGPT, llama_index takes in your question retrieves the chunks of vectors from the parsed file that are relevant to your prompt using <a href="https://www.pinecone.io/learn/what-is-similarity-search/">similarity search</a></p>
</li>
<li>
<p>Once it retrieves the relevant chunks, llama_index overrides your original prompt by adding what it retrieved as the context to the model.</p>
</li>
<li>
<p>With the original question and the context it just has been provided with, ChatGPT should be able to understand your question.</p>
</li>
</ul>
<p>And voila! you’ll get a relevant response from ChatGPT. This is how llama_index makes LLMs understand custom knowledge. There’s more to this and new features are getting added to llama_index everyday. Make sure you explore more of what it could do.</p>
<hr>
<p>Now, that’s about llama_index. In the next blog of this series. We’ll see how to use langchain to build a more robust chatbot framework that keeps track of the previous conversations it had with the user. See ya in the next one :wink:</p> </div> <script id="mathjax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script> <div class="text-center mt-8"> <a href="/blog" class="bg-gray-100 px-5 py-3 rounded-md hover:bg-gray-200 transition">← Back to Blog</a> </div>  </div>  <footer class="my-20"> <p class="text-center text-sm text-slate-500">
Copyright © 2024 NuNmi.ai. All rights reserved.
</p> <p class="text-center text-xs text-slate-500 mt-1">
Designed and developed by <a href="https://nunmi.ai" target="_blank" rel="noopener" class="hover:underline">
NuNmi.ai
</a> </p> </footer>  </body> </html>